{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AgeClassifier.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Ro-2PDN1osXM","colab_type":"code","colab":{}},"source":["from IPython.display import clear_output\n","!pip install --upgrade tensorflow-gpu\n","!pip install --upgrade tqdm\n","clear_output()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MaqVduZ2qMrk","colab_type":"code","colab":{}},"source":["#Downloads and extract Dataset to local, wait for download, i dont want to put a progress bar here sorry\n","#You can run this on google colab for get faster downloads speeds\n","import os\n","import tarfile\n","import requests\n","from tqdm import tqdm\n","\n","folder_path = \"./Datasets\"\n","\n","wiki_url = \"https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/static/wiki_crop.tar\"\n","wiki_path = folder_path + '/wiki.tar.gz'\n","\n","imdb_url = \"https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/static/imdb_crop.tar\"\n","imdb_path = folder_path + '/imdb.tar.gz'\n","\n","if(not os.path.exists(folder_path)):\n","  os.mkdir(folder_path)\n","\n","if(not(os.path.exists(wiki_path) and os.path.isfile(wiki_path))):\n","  resp = requests.get(wiki_url, stream=True)\n","\n","  total_size = int(resp.headers.get('content-length', 0))\n","  block_size = 16384\n","  t=tqdm(total=total_size, unit='iB', unit_scale=True)\n","  \n","  with open(wiki_path, \"wb\") as f:\n","    for data in resp.iter_content(block_size):\n","      t.update(len(data))\n","      f.write(data)\n","    t.close()\n","    f.close()\n","\n","    if total_size != 0 and t.n != total_size:\n","      print(\"Wiki Faces Download Error\")\n","\n","  tar = tarfile.open(wiki_path, \"r\")\n","  tar.extractall(folder_path)\n","  tar.close()\n","\n","  os.remove(\"./Datasets/wiki_crop/wiki.mat\")\n","\n","\n","\n","if(not(os.path.exists(imdb_path) and os.path.isfile(imdb_path))):\n","  resp = requests.get(imdb_url, stream=True)\n","\n","  total_size = int(resp.headers.get('content-length', 0))\n","  block_size = 16384\n","  t=tqdm(total=total_size, unit='iB', unit_scale=True)\n","  \n","  with open(imdb_path, \"wb\") as f:\n","    for data in resp.iter_content(block_size):\n","      t.update(len(data))\n","      f.write(data)\n","    t.close()\n","    f.close()\n","\n","    if total_size != 0 and t.n != total_size:\n","      print(\"Imdb Faces Download Error\")\n","\n","  tar = tarfile.open(imdb_path, \"r\")\n","  tar.extractall(folder_path)\n","  tar.close()\n","\n","  os.remove(\"./Datasets/imdb_crop/imdb.mat\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0xreyHjck7yp","colab_type":"code","colab":{}},"source":["#Imports\n","import tensorflow as tf\n","import numpy as np\n","import pandas as pd"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"g8kNBUzqjk8I","colab_type":"code","colab":{}},"source":["root = \"./Datasets\"\n","folders = os.listdir(root)\n","\n","if(not (\"dataset.csv\" in folders)):\n","  folders.remove(\"imdb.tar.gz\")\n","  folders.remove(\"wiki.tar.gz\")\n","\n","  data = list()\n","\n","  for folder in folders:\n","    subfolders = os.listdir(\"{root}/{folder}\".format(root=root, folder=folder))\n","    for subfolder in subfolders:\n","      files = os.listdir(\"{root}/{folder}/{subfolder}\".format(root=root, folder=folder, subfolder=subfolder))\n","      for file in files:\n","        path = \"{root}/{folder}/{subfolder}/{file}\".format(root=root, folder=folder, subfolder=subfolder, file=file)\n","\n","        try:\n","          file_data = file[:-4]\n","          file_data = file_data.split(\"_\")\n","\n","          if(folder == \"wiki_crop\"):\n","            id = file_data[0]\n","            born = int(file_data[1].split(\"-\")[0])\n","          else:\n","            id = file_data[0][2:]\n","            born = int(file_data[2].split(\"-\")[0])\n","\n","          taken = int(file_data[-1])\n","          age = taken - born\n","\n","          data.append([id, age, path])\n","        except:\n","          print(\"error\")\n","          \n","\n","  df = pd.DataFrame(data=data, columns=[\"personId\", \"age\", \"url\"])\n","  df.to_csv(root + \"/dataset.csv\")\n","  df.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pQGcLf2NQDTG","colab_type":"code","colab":{}},"source":["#Load csv\n","faces_df = pd.read_csv(\"./Datasets/dataset.csv\")"],"execution_count":0,"outputs":[]}]}