{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AgeClassifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ElPapi42/AgeClassifier/blob/master/AgeClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ro-2PDN1osXM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import clear_output\n",
        "!pip install --upgrade tensorflow-gpu\n",
        "!pip install --upgrade tqdm\n",
        "!pip install --upgrade pillow\n",
        "!pip install git+https://github.com/Jwink3101/parmapper\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xreyHjck7yp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Imports\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from parmapper import parmap\n",
        "import sys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RD84h7pWVqU",
        "colab_type": "text"
      },
      "source": [
        "## Data Download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaqVduZ2qMrk",
        "colab_type": "code",
        "outputId": "49308af0-de51-4ac8-f5b9-d7de044d9549",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "#Downloads and extract Dataset to local, wait for download, i dont want to put a progress bar here sorry\n",
        "#You can run this on google colab for get faster downloads speeds\n",
        "import os\n",
        "import tarfile\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "\n",
        "folder_path = \"./Datasets\"\n",
        "\n",
        "wiki_url = \"https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/static/wiki_crop.tar\"\n",
        "wiki_path = folder_path + '/wiki.tar.gz'\n",
        "\n",
        "imdb_url = \"https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/static/imdb_crop.tar\"\n",
        "imdb_path = folder_path + '/imdb.tar.gz'\n",
        "\n",
        "#Create Dataset folder if not exists\n",
        "if(not os.path.exists(folder_path)):\n",
        "  os.mkdir(folder_path)\n",
        "\n",
        "#download wikipedia faces dataset\n",
        "if(not(os.path.exists(wiki_path) and os.path.isfile(wiki_path))):\n",
        "  resp = requests.get(wiki_url, stream=True)\n",
        "\n",
        "  total_size = int(resp.headers.get('content-length', 0))\n",
        "  block_size = 16384\n",
        "  t=tqdm(total=total_size, unit='iB', unit_scale=True)\n",
        "  \n",
        "  with open(wiki_path, \"wb\") as f:\n",
        "    for data in resp.iter_content(block_size):\n",
        "      t.update(len(data))\n",
        "      f.write(data)\n",
        "    t.close()\n",
        "    f.close()\n",
        "\n",
        "    if total_size != 0 and t.n != total_size:\n",
        "      print(\"Wiki Faces Download Error\")\n",
        "\n",
        "#download imdb faces dataset\n",
        "if(not(os.path.exists(imdb_path) and os.path.isfile(imdb_path))):\n",
        "  resp = requests.get(imdb_url, stream=True)\n",
        "\n",
        "  total_size = int(resp.headers.get('content-length', 0))\n",
        "  block_size = 16384\n",
        "  t=tqdm(total=total_size, unit='iB', unit_scale=True)\n",
        "  \n",
        "  with open(imdb_path, \"wb\") as f:\n",
        "    for data in resp.iter_content(block_size):\n",
        "      t.update(len(data))\n",
        "      f.write(data)\n",
        "    t.close()\n",
        "    f.close()\n",
        "\n",
        "    if total_size != 0 and t.n != total_size:\n",
        "      print(\"Imdb Faces Download Error\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 811M/811M [00:23<00:00, 34.0MiB/s]\n",
            "100%|██████████| 7.01G/7.01G [06:23<00:00, 18.3MiB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCj1XMAxeujx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Extract Datasets\n",
        "\n",
        "#Wikipedia Dataset\n",
        "tar = tarfile.open(wiki_path, \"r\")\n",
        "tar.extractall(folder_path)\n",
        "tar.close()\n",
        "os.remove(\"./Datasets/wiki_crop/wiki.mat\")\n",
        "\n",
        "#IMDB Dataset\n",
        "tar = tarfile.open(imdb_path, \"r\")\n",
        "tar.extractall(folder_path)\n",
        "tar.close()\n",
        "os.remove(\"./Datasets/imdb_crop/imdb.mat\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuJCEQWQsX_H",
        "colab_type": "code",
        "outputId": "3d08e090-dca6-4ac0-f45d-3ac8b84e0291",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def preproc(filepath):\n",
        "  try:\n",
        "    #Check if the image is corrupted\n",
        "    Image.open(filepath)\n",
        "\n",
        "    filename = filepath[:-4].split(\"/\")[-1]\n",
        "    folder = filepath[:-4].split(\"/\")[1]\n",
        "    file_data = filename.split(\"_\")\n",
        "\n",
        "    if(folder == \"wiki_crop\"):\n",
        "      id = \"w\" + file_data[0]\n",
        "      born = int(file_data[1].split(\"-\")[0])\n",
        "    else:\n",
        "      id = \"i\" + file_data[0][2:]\n",
        "      born = int(file_data[2].split(\"-\")[0])\n",
        "\n",
        "    taken = int(file_data[-1])\n",
        "    age = taken - born\n",
        "    age = str(age)\n",
        "\n",
        "    return [id, age, filepath]\n",
        "  except OSError:\n",
        "    os.remove(filepath)\n",
        "\n",
        "#Find urls\n",
        "root = \"./Datasets\"\n",
        "folders = os.listdir(root)\n",
        "\n",
        "if(not (\"dataset.csv\" in folders)):\n",
        "\n",
        "  folders.remove(\"imdb.tar.gz\")\n",
        "  folders.remove(\"wiki.tar.gz\")\n",
        "\n",
        "  urls = list()\n",
        "\n",
        "  for folder in folders:\n",
        "    subfolders = os.listdir(\"{root}/{folder}\".format(root=root, folder=folder))\n",
        "    for subfolder in subfolders:\n",
        "      files = os.listdir(\"{root}/{folder}/{subfolder}\".format(root=root, folder=folder, subfolder=subfolder))\n",
        "      for file in files:\n",
        "        path = \"{root}/{folder}/{subfolder}/{file}\".format(root=root, folder=folder, subfolder=subfolder, file=file)\n",
        "        urls.append(path)\n",
        "\n",
        "  #Extract ids and age from images file names\n",
        "  processed = list(parmap(preproc, urls, progress=True))\n",
        "  faces_df = pd.DataFrame(processed, columns=[\"id\", \"age\", \"url\"])\n",
        "  faces_df.to_csv(root + \"/dataset.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqc3wjcDWlK-",
        "colab_type": "text"
      },
      "source": [
        "## Exploratory Data analysis and Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwVRhdxgT9YU",
        "colab_type": "code",
        "outputId": "7e019a12-4019-44b9-a76f-4b01511f5d96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "#Load csv\n",
        "faces_df = pd.read_csv(\"./Datasets/dataset.csv\")\n",
        "\n",
        "#Shuffle\n",
        "faces_df = faces_df.sample(frac=1.0)\n",
        "faces_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>170536</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132941</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>370583</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>435864</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>405408</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         0   1\n",
              "170536 NaN NaN\n",
              "132941 NaN NaN\n",
              "370583 NaN NaN\n",
              "435864 NaN NaN\n",
              "405408 NaN NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xU9o4MVJUkTZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "faces_df.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qElqE0dCbz7T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Lets see some examples\n",
        "plt.figure(figsize=(10,10))\n",
        "for i, path in enumerate(faces_df[\"url\"].iloc[:9]):\n",
        "    img = tf.keras.preprocessing.image.load_img(path)\n",
        "    plt.subplot(3,3,i+1)\n",
        "    plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opR4m_EQTpXO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Check descriptive statistics\n",
        "faces_df.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kesj6xY0T-2s",
        "colab_type": "text"
      },
      "source": [
        "High Precense of outliers, lets fix that"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-CREs_1UFkJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Clear Dataset from outliers\n",
        "age_up_0 = faces_df[\"age\"] > 0\n",
        "age_down_75 = faces_df[\"age\"] < 75\n",
        "faces_df = faces_df[age_up_0 & age_down_75]\n",
        "faces_df.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOCbNQaHRLxo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Check for how much unique people is here\n",
        "id_count = faces_df[\"personId\"].nunique()\n",
        "\"The Dataset contains {count} unique persons across its images\".format(count=id_count)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PKWR_RHTPEK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Lets see the distribution of the age across our dataset\n",
        "sns.distplot(faces_df[\"age\"], bins=75)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYqPpc-XYX0-",
        "colab_type": "text"
      },
      "source": [
        "## Dataset Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5g8jH-s3WFte",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Split dataset between train, eval and test\n",
        "full_df = faces_df\n",
        "eval_df = full_df.sample(frac=0.05)\n",
        "full_df = full_df.drop(eval_df.index)\n",
        "test_df = full_df.sample(frac=0.05)\n",
        "train_df = full_df.drop(test_df.index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TI12KRHSaNE_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Store number of datapoints in each dataset\n",
        "train_count = train_df.shape[0]\n",
        "eval_count = eval_df.shape[0]\n",
        "test_count = test_df.shape[0]\n",
        "print(\"Train samples: \" + str(train_count))\n",
        "print(\"Evaluation samples: \" + str(eval_count))\n",
        "print(\"Test samples: \" + str(test_count))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1W3_o6bEaWKC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Verify the distribution of the three splits\n",
        "sns.distplot(a=train_df[\"age\"], bins=75).set_title(\"Users Distribution\")\n",
        "sns.distplot(a=eval_df[\"age\"], bins=75)\n",
        "sns.distplot(a=test_df[\"age\"], bins=75)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHSHNXDelIum",
        "colab_type": "text"
      },
      "source": [
        "## Dataset Creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bELKxoRglHgP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Generator funcion\n",
        "tf.train."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0r7NaXWjytq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create Datasets for train, evaluation and testing\n",
        "train_ds = tf.data.Dataset.from_tensor_slices().shuffle(4196)\n",
        "eval_ds = tf.data.Dataset.from_tensor_slices().batch(eval_count)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices().batch(test_count)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}